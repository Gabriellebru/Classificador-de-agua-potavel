// This file was auto-generated by ML.NET Model Builder. 

using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
using Microsoft.ML;
using Classificador_de_agua_potavelML.Model;

namespace Classificador_de_agua_potavelML.Model
{
    public class ConsumeModel
    {
        private static Lazy<PredictionEngine<ModelInput, ModelOutput>> PredictionEngine = new Lazy<PredictionEngine<ModelInput, ModelOutput>>(CreatePredictionEngine);

        // For more info on consuming ML.NET models, visit https://aka.ms/mlnet-consume
        // Method for consuming model in your app
        public static ModelOutput Predict(ModelInput input)
        {
            ModelOutput result = PredictionEngine.Value.Predict(input);
            return result;
        }

        public static List<ModelOutput> Predicts(List<ModelInput> inputs)
        {
            List<ModelOutput> outputs = new List<ModelOutput>();
            foreach (var input in inputs)
            {
                outputs.Add(Predict(input));
            }
            return outputs;
        }

        public static void ShowResult(ModelOutput output)
        {
            var prediction = output.Prediction == "0" ? "não é potável" : "é potável";
            Console.WriteLine($"A água {prediction}");
        }

        public static void ShowResults(List<ModelOutput> outputs)
        {
            foreach (var output in outputs)
            {
                ShowResult(output);
            }
        }

        public static PredictionEngine<ModelInput, ModelOutput> CreatePredictionEngine()
        {
            // Create new MLContext
            MLContext mlContext = new MLContext();

            // Load model & create prediction engine
            string modelPath = @"C:\Users\gabri\AppData\Local\Temp\MLVSTools\Classificador de agua potavelML\Classificador de agua potavelML.Model\MLModel.zip";
            ITransformer mlModel = mlContext.Model.Load(modelPath, out var modelInputSchema);
            var predEngine = mlContext.Model.CreatePredictionEngine<ModelInput, ModelOutput>(mlModel);

            return predEngine;
        }
    }
}
